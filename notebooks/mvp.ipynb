{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "_This is your space to describe your intentions for the project, before writing a single line of code. What are you studying? What are you hoping to build? If you can't explain that clearly before you start digging into the data, you're going to have a hard time planning where to go with this._\n",
    "\n",
    "_Done? Great. Now use the following cells as a guide as you work through your Minimum Viable Product. Remember, the purpose of the MVP is not to put together a solution that's ready to be published! This is your chance to take a quick pass through the data, run it through a simple model, and get some preliminary results. When this phase is over, you'll have an end-to-end pipeline and a basic understanding of the problem. Then you'll be able to iterate on each stage as you improve your research and find better and better insights._\n",
    "\n",
    "_At the start of each code cell there is a `%%writefile` command that is commented out twice. When you're done building your MVP, uncomment these lines and run the cells again. (Remember to run the entire notebook once before doing this to make sure that your code works!) These commands will export your code cells to python scripts in the `src` directory. The last cell will build a `main.py` script in the top level directory that can be run to execute the entire pipeline._\n",
    "\n",
    "\n",
    "_Note that for this to work, you'll either need to include your import statements in the code cells where they're used, or you'll need to go through the generated scripts manually and make sure they have everything they need to run. You will also need to be careful about sharing variable names across cells, since they won't be accessible when the code is exported to separate scripts. Work with these cells as if each one is an independent Python script._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "_Describe your data sources here and explain why they are relevant to the problem you are trying to solve._\n",
    "\n",
    "_Write code here to download your data and save it in data/external. If you've got the data from an offline source, describe where it came from and what the files look like. Right now we're only care about getting the raw data files.  Don't do anything to them just yet, just download them and save them in the same format you find them!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# data = some file I'm downloading from somewhere\n",
    "\n",
    "# with open(\"../data/raw/my_raw_data.txt\", \"wb\") as filepath:\n",
    "#     filepath.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "_Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what others may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?_\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems moving forward as you visualize and model your data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "\n",
    "# with open(\"../data/raw/my_raw_name.txt\", \"rb\") as filepath:\n",
    "#     raw_data = filepath.read(data)\n",
    "\n",
    "# (DATA CLEANING CODE GOES HERE)\n",
    "\n",
    "## If any of your data processing steps take a long time to run, save their outputs in the data/interim directory.\n",
    "## Then in the future you will be able to access them from there, and save time waiting for code to run again.\n",
    "# with open(\"../data/interim/my_interim_data.txt\", \"wb\") as filepath:\n",
    "#     filepath.write(data)\n",
    "\n",
    "# (FEATURE ENGINEERING CODE GOES HERE)\n",
    "\n",
    "## Note that I prefer working with tab-delimited tsv's instead of the more common csv's, \n",
    "## but that's my personal preference.\n",
    "# my_dataframe.to_csv(\"../data/processed/my_dataframe.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "_Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense._\n",
    "\n",
    "_Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "## Note that cookiecutter does not create a file for exploratory descriptive statistics. \n",
    "## You may want to create one if you think it's needed. So far I'm not entirely sure it's necessary.\n",
    "\n",
    "# (DESCRIPTIVE STATISTICS CODE GOES HERE)\n",
    "# with open(\"../reports/descriptive_statistics.txt\", \"wb\") as filepath:\n",
    "#     filepath.write(exploratory_summary)\n",
    "\n",
    "# (VISUALIZATION CODE GOES HERE)\n",
    "# plt.savefig('../reports/figures/exploratory_analysis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What did you learn? What relationships do you think will be most helpful as you build your model?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "_Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "## (TRAIN/TEST SPLIT CODE GOES HERE)\n",
    "\n",
    "# training_data.to_csv(\"../data/processed/train.tsv\", sep=\"\\t\")\n",
    "# test_data.to_csv(\"../data/processed/test.tsv\", sep=\"\\t\")\n",
    "## Suggestion: since it's bad practice to look at test data once it's been created, \n",
    "## consider saving the test data in a pickle file instead of a tsv.\n",
    "\n",
    "## (MODEL TRAINING CODE GOES HERE)\n",
    "\n",
    "# with open(\"../models/my_model.pkl\", \"wb\") as filepath:\n",
    "#     pickle.dump(my_model, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# pd.read_csv(\"../data/processed/test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# with open(\"../models/my_model.pkl\", \"rb\") as filepath:\n",
    "#     my_model = pickle.load(filepath)\n",
    "\n",
    "## (MODEL PREDICTION + EVALUATION CODE GOES HERE)\n",
    "\n",
    "# with open(\"../reports/model_performance.txt\", \"wb\") as filepath:\n",
    "#     filepath.write(performance_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
